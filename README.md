

# ðŸ“˜ Project Documentation: Predictive Maintenance with MLOps

## **0. Purpose of the Application**

The purpose of this application is to build a **predictive maintenance system** capable of forecasting machine failures before they occur. It implements a full **MLOps pipeline** to ensure that data processing, model development, deployment, monitoring, and automation are performed in a scalable, reproducible, and production-ready manner. The system supports continuous integration, versioning, containerization, cloud deployment, and real-time monitoring of model performance.

---

## **1. Data Ingestion**

**Objective:** Acquire raw machine operating data from a MySQL database and convert it into a clean, structured format suitable for preprocessing and modeling.

**Highlights:**

* Connects to a MySQL database.
* Loads raw data into a tabular structure.
* Saves the ingested data into a CSV format for versioning and reuse.
* Integrated logging and exception handling to ensure reliability.

**Tools Used:**
MySQL, SQLAlchemy, MySQL-connector, Pandas.

---

## **2. Data Transformation**

**Objective:** Prepare and enhance the dataset to improve model performance during training.

**Main Steps:**

1. **Feature Engineering** â€“ Creates a new calculated feature:
   *Power = Torque Ã— Rotational Speed*
2. **Feature Selection** â€“ Removes redundant or irrelevant variables.
3. **Outlier Removal** â€“ Applies IQR-based filtering.
4. **Encoding** â€“ Converts categorical attributes into numerical format.
5. **Variable Separation** â€“ Defines features (X) and target (y).
6. **Class Balancing** â€“ Uses SMOTE to address class imbalance issues.
7. **Data Splitting** â€“ Divides data into 70% training and 30% testing sets.

**Tools Used:**
Pandas, Scikit-learn, Imbalanced-Learn (SMOTE).

---

## **3. Model Training**

**Objective:** Train a machine learning model capable of predicting equipment failures accurately.

**Details:**

* Utilizes **RandomForestClassifier** for robust performance.
* Applies tuned hyperparameters.
* Stores the final trained model in serialized format for deployment.

**Tools Used:**
Scikit-learn, Pickle.

---

## **4. Model Evaluation**

**Objective:** Assess model performance using standard classification metrics.

**Metrics Evaluated:**

* Accuracy
* Precision
* Recall
* F1-Score

All evaluation results are logged and stored for experiment tracking.

**Tools Used:**
Scikit-learn (metrics).

---

## **5. Data & Model Versioning**

**Objective:** Ensure reproducibility and traceability across datasets, model versions, and code.

**Tools Used:**

* **DVC** â€“ Tracks datasets and intermediate artifacts.
* **Git** â€“ Version control for source code.
* **Dagshub** â€“ Centralized platform for managing code, data, models, and experiments.

---

## **6. Experiment Tracking**

**Objective:** Log and manage model training experiments, parameters, metrics, and artifacts.

**Tools Used:**

* **MLflow** integrated with Dagshub:

  * Tracks model parameters and metrics.
  * Stores artifacts such as evaluation reports.
  * Manages model registry for versioning.

---

## **7. Model Deployment**

**Objective:** Deploy the trained model as a cloud-based service for real-world usage.

**Deployment Workflow:**

1. **Containerization:**
   The entire application is containerized using Docker.

2. **Cloud Deployment:**
   The Docker image is pushed to **Azure Container Registry** and deployed via **Azure Web App**.

3. **Continuous Integration / Continuous Deployment (CI/CD):**
   GitHub Actions automates:

   * Building Docker images
   * Running tests
   * Pushing images to Azure
   * Deploying the updated application

**Tools Used:**
Docker, Azure Container Registry, Azure Web App, GitHub Actions.

---

## **8. Monitoring**

**Objective:** Continuously observe model performance and detect drift after deployment.

**Monitoring Workflow:**

* Predictions generated by the model are logged in a MySQL database.
* **EvidentlyAI** is used to detect:

  * Data drift
  * Concept drift
  * Performance degradation

This enables proactive retraining and maintenance of the ML pipeline.

**Tools Used:**
MySQL, EvidentlyAI.

---

## **9. Testing & Automation**

**Objective:** Ensure reliability, code quality, and automated workflow execution.

**Components:**

* **Pytest** â€“ Unit tests to verify presence and correctness of artifacts such as trained models.
* **GitHub Actions** â€“ Automates testing, building, and deployment steps.

---

# ðŸ“Š End-to-End Workflow Summary

1. **Data Ingestion:** Collect data from MySQL and save as CSV.
2. **Data Transformation:** Clean, engineer features, balance classes, and split data.
3. **Model Training:** Train RandomForest model and save it.
4. **Evaluation:** Compute classification metrics.
5. **Versioning & Tracking:** Use Git, DVC, Dagshub, and MLflow.
6. **Deployment:** Containerize and deploy to Azure using CI/CD.
7. **Monitoring:** Detect drift using EvidentlyAI with results stored in MySQL.

---

âœ… This end-to-end MLOps pipeline ensures **automation, transparency, reproducibility, scalability, and continuous monitoring** of the predictive maintenance system.
